#!/usr/bin/env python3

# -*- coding: utf-8 -*-

import numpy as np
import pyaudio
from scipy.fftpack import fft
from scipy.signal import welch, butter, sosfilt
import time
import sys
from collections import deque
from enum import Enum
from threading import Thread
import requests
import json
import threading

# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –î–õ–Ø RASPBERRY PI

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–∞
BUFFER_SIZE = 2048
SAMPLE_RATE = 44100
FFT_SIZE = 1024
WELCH_SEGMENT = 512
WELCH_OVERLAP = 256

# –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä
SEND_INTERVAL_NORMAL = 2.0      # 2 —Å–µ–∫ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥—Ä–æ–Ω–∞
SEND_INTERVAL_DETECTED = 0.5    # 0.5 —Å–µ–∫ –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏

# –¢–∏–ø—ã –¥—Ä–æ–Ω–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
class DroneType(Enum):
    UNKNOWN = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    SMALL = "–ú–∞–ª–µ–Ω—å–∫–∏–π –¥—Ä–æ–Ω"
    MEDIUM = "–°—Ä–µ–¥–Ω–∏–π –¥—Ä–æ–Ω"
    LARGE = "–ë–æ–ª—å—à–æ–π –¥—Ä–æ–Ω"

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥—Ä–æ–Ω–æ–≤
DRONE_PROFILES = {
    DroneType.SMALL: {
        'bands': [(7500, 8000, 0.5), (14500, 15500, 0.5), (0, 500, 1)],
        'fundamental_range': (80, 300),
        'harmonic_count': 4,
        'noise_factor': 0.3
    },
    DroneType.MEDIUM: {
        'bands': [(6500, 7500, 0.4), (12500, 14000, 0.4), (10000, 12000, 0.3), (0, 400, 0.8)],
        'fundamental_range': (60, 200),
        'harmonic_count': 5,
        'noise_factor': 0.25
    },
    DroneType.LARGE: {
        'bands': [(5000, 7000, 0.3), (9500, 11500, 0.3), (13500, 14500, 0.3), (0, 300, 0.6)],
        'fundamental_range': (40, 120),
        'harmonic_count': 6,
        'noise_factor': 0.2
    }
}

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
HARMONICS_CHECK = True
USE_WELCH = True
ADAPTIVE_THRESHOLDS = True

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
HARMONIC_HISTORY_SIZE = 40
CONFIRMATION_THRESHOLD = 0.35  

# Butterworth —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è (HIGH-PASS 80Hz)
butter_sos = butter(2, 80, btype='high', fs=SAMPLE_RATE, output='sos')

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è PyAudio
audio_engine = pyaudio.PyAudio()

# –ò—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
harmonic_history = deque(maxlen=HARMONIC_HISTORY_SIZE)
frequency_history = deque(maxlen=15)
noise_floor_history = deque(maxlen=100)
detected_drone_history = deque(maxlen=20)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
detected_drone_type = DroneType.UNKNOWN
detection_confidence = 0.0
current_fundamental_freq = None
adaptive_threshold_factor = 1.0
last_detection_time = 0

# –§–ª–∞–≥–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
running = True
detection_active = False


# –§–£–ù–ö–¶–ò–ò –û–¢–ü–†–ê–í–ö–ò –ù–ê –°–ï–†–í–ï–†

# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–ï–†–í–ï–†–ê
SERVER_URL = "http://192.168.0.223:5000/api/update" 
INSTALLATION_ID = "north"  # ‚Üê north, east, south, west

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
last_sent_status = None
send_lock = threading.Lock()
last_send_time = 0

def send_to_server(detected, frequency, drone_type, confidence): #–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –Ω–∞ —Å–µ—Ä–≤–µ—Ä —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    global last_sent_status, last_send_time
    
    current_time = time.time()
    
    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –æ—Ç–ø—Ä–∞–≤–∫–∏
    send_interval = SEND_INTERVAL_DETECTED if detected else SEND_INTERVAL_NORMAL
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª—Å—è —Å—Ç–∞—Ç—É—Å –∏–ª–∏ –ø—Ä–æ—à–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏
    if (detected != last_sent_status or current_time - last_send_time > send_interval):
        try:
            payload = {
                "installation_id": INSTALLATION_ID,
                "detected": detected,
                "frequency": float(frequency) if frequency else 0.0,
                "confidence": float(confidence) if confidence else 0.0,
                "timestamp": time.time()
            }
            
            response = requests.post(
                SERVER_URL,
                json=payload,
                timeout=3
            )
            
            if response.status_code == 200:
                print(f"‚úì –°–µ—Ä–≤–µ—Ä: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ={detected}")
                last_sent_status = detected
                last_send_time = current_time
            else:
                print(f"‚úó –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: HTTP {response.status_code}")
        
        except requests.exceptions.ConnectTimeout:
            print(f"‚úó –¢–∞–π–º–∞—É—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è")
        except requests.exceptions.ReadTimeout:
            print(f"‚úó –¢–∞–π–º–∞—É—Ç —á—Ç–µ–Ω–∏—è")
            last_sent_status = detected
            last_send_time = current_time
        except requests.exceptions.ConnectionError:
            print(f"‚úó –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ IP —Å–µ—Ä–≤–µ—Ä–∞")
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {type(e).__name__}")

# –§–£–ù–ö–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò –°–ü–ï–ö–¢–†–ê

def compute_welch_spectrum(audio_data, fs, nperseg=512, noverlap=256): #–í—ã—á–∏—Å–ª—è–µ—Ç —Å–ø–µ–∫—Ç—Ä –º–µ—Ç–æ–¥–æ–º –£—ç–ª—á–∞
    f, Pxx = welch(audio_data, fs=fs, nperseg=nperseg,
                   noverlap=noverlap, nfft=FFT_SIZE,
                   scaling='spectrum', window='hann')
    magnitude = np.sqrt(Pxx)
    magnitude_log = np.log1p(magnitude * 1000)
    return f, magnitude_log[:len(f)]

def update_noise_floor(spectrum, freq_axis): #–û–±–Ω–æ–≤–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞
    high_freq_mask = freq_axis > 10000
    if np.any(high_freq_mask):
        noise_level = np.median(spectrum[high_freq_mask])
        noise_floor_history.append(noise_level)
        return noise_level
    return 0.0

def get_adaptive_threshold(base_threshold): #–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Ä–æ–≥ —Å —É—á—ë—Ç–æ–º —É—Ä–æ–≤–Ω—è —à—É–º–∞
    if not ADAPTIVE_THRESHOLDS or len(noise_floor_history) < 10:
        return base_threshold
    
    current_noise = np.median(list(noise_floor_history)[-10:])
    adaptive_factor = 1.0 + (current_noise * 0.5)
    return base_threshold * adaptive_factor

def classify_drone_type(peak_freqs, peak_vals, fundamental_freq, spectrum, freq_axis): #–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–∏–ø –¥—Ä–æ–Ω–∞ –ø–æ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º
    scores = {}
    
    for drone_type, profile in DRONE_PROFILES.items():
        score = 0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–π —á–∞—Å—Ç–æ—Ç—ã
        freq_low, freq_high = profile['fundamental_range']
        if freq_low <= fundamental_freq <= freq_high:
            score += 0.3
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã—Ö –ø–æ–ª–æ—Å
        band_score = 0
        for band_low, band_high, _ in profile['bands']:
            band_mask = (freq_axis >= band_low) & (freq_axis <= band_high)
            if np.any(band_mask):
                band_power = np.mean(spectrum[band_mask])
                if band_power > get_adaptive_threshold(0.2):
                    band_score += 1
        
        score += (band_score / len(profile['bands'])) * 0.4
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∏–∫–æ–≤
        if len(peak_freqs) >= profile['harmonic_count']:
            score += 0.3
        
        scores[drone_type] = score
    
    # –í—ã–±–∏—Ä–∞–µ–º —Ç–∏–ø —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º score
    best_type = max(scores, key=scores.get)
    if scores[best_type] > 0.5:
        return best_type
    
    return DroneType.UNKNOWN

def calculate_confidence(harmonics_found, total_harmonics, fundamental_amp, drone_type): #–í—ã—á–∏—Å–ª—è–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
    harmonic_ratio = harmonics_found / total_harmonics if total_harmonics > 0 else 0
    confidence = harmonic_ratio * 0.6
    
    amp_factor = min(fundamental_amp / 1.0, 1.0)
    confidence += amp_factor * 0.2
    
    # –£—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —á–∞—Å—Ç–æ—Ç—ã
    if len(frequency_history) >= 3:
        recent = list(frequency_history)[-3:]
        if np.std(recent) < 50:
            confidence += 0.2
    
    return min(confidence, 1.0)

def check_harmonics_with_delay_enhanced(frequency_axis, magnitude_log): #–ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–∞—Ä–º–æ–Ω–∏–∫ —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π —Ç–∏–ø–∞ –¥—Ä–æ–Ω–∞
    global detected_drone_type, detection_confidence, adaptive_threshold_factor
    
    # 1. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    overall_volume = np.max(magnitude_log)
    if overall_volume < get_adaptive_threshold(0.3):  
        harmonic_history.append(False)
        return False, None, DroneType.UNKNOWN, 0.0
    
    # 2. –û–±–Ω–æ–≤–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —à—É–º–∞
    update_noise_floor(magnitude_log, frequency_axis)
    
    # 3. –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–∏ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
    peak_indices = []
    peak_values = []
    peak_frequencies = []
    
    adaptive_peak_threshold = get_adaptive_threshold(0.4)  
    
    for i in range(10, len(magnitude_log) - 10):
        if magnitude_log[i] > adaptive_peak_threshold:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ø–∏–∫
            is_peak = True
            for offset in range(1, 11):  
                if magnitude_log[i] <= magnitude_log[i - offset] or \
                   magnitude_log[i] <= magnitude_log[i + offset]:
                    is_peak = False
                    break
            
            if is_peak and magnitude_log[i] > adaptive_peak_threshold * 1.2:  
                peak_indices.append(i)
                peak_values.append(magnitude_log[i])
                peak_frequencies.append(frequency_axis[i])
    
    # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –ø–∏–∫–æ–≤
    if len(peak_indices) < 3:  
        harmonic_history.append(False)
        return False, None, DroneType.UNKNOWN, 0.0
    
    # 4. –ù–∞—Ö–æ–¥–∏–º –æ—Å–Ω–æ–≤–Ω—É—é —á–∞—Å—Ç–æ—Ç—É
    fundamental_freq = None
    fundamental_val = 0
    fundamental_idx = -1
    
    for idx, freq in enumerate(peak_frequencies):
        if 30 < freq < 1000:
            if peak_values[idx] > fundamental_val:
                fundamental_val = peak_values[idx]
                fundamental_freq = freq
                fundamental_idx = idx
    
    if fundamental_freq is None or fundamental_freq < 30:
        harmonic_history.append(False)
        return False, None, DroneType.UNKNOWN, 0.0
    
    # 5. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥—Ä–æ–Ω–∞
    drone_type = classify_drone_type(peak_frequencies, peak_values, fundamental_freq,
                                     magnitude_log, frequency_axis)
    
    # 6. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–∞—Ä–º–æ–Ω–∏–∫–∏
    profile = DRONE_PROFILES.get(drone_type, DRONE_PROFILES[DroneType.SMALL])
    harmonic_ratios = list(range(2, profile['harmonic_count'] + 2))
    
    harmonics_found = 0
    harmonic_matches = []
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∞–º–ø–ª–∏—Ç—É–¥—ã
    normalized_peaks = []
    for i in range(len(peak_frequencies)):
        normalized = peak_values[i] / fundamental_val if fundamental_val > 0 else 0
        normalized_peaks.append((peak_frequencies[i], normalized, peak_values[i]))
    
    for ratio in harmonic_ratios:
        target_freq = fundamental_freq * ratio
        
        # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π –ø–∏–∫
        closest_peak = None
        min_diff = float('inf')
        
        for freq, norm, val in normalized_peaks:
            if freq < 50:
                continue
            
            freq_diff = abs(freq - target_freq)
            relative_diff = freq_diff / target_freq
            
            tolerance = 0.05 if ratio <= 4 else 0.07 
            
            if relative_diff < tolerance and freq_diff < min_diff:
                min_diff = freq_diff
                closest_peak = (freq, norm, val)
        
        if closest_peak and closest_peak[1] > 0.15: 
            harmonics_found += 1
            harmonic_matches.append((ratio, closest_peak[0], closest_peak[1]))
    
    # 7. –í—ã—á–∏—Å–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    confidence = calculate_confidence(harmonics_found, len(harmonic_ratios),
                                     fundamental_val, drone_type)
    
    # 8. –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
    current_result = False
    min_harmonics_required = 2 if drone_type == DroneType.SMALL else 1 
    
    if (harmonics_found >= min_harmonics_required and
        fundamental_val > get_adaptive_threshold(0.5)): 
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —á–∞—Å—Ç–æ—Ç—ã
        if len(frequency_history) >= 5:
            recent_freqs = list(frequency_history)[-5:]
            freq_std = np.std(recent_freqs)
            if freq_std < 100:
                current_result = True
        elif len(frequency_history) > 0:
            current_result = True
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞—Å—Ç–æ—Ç—É –≤ –∏—Å—Ç–æ—Ä–∏—é
    frequency_history.append(fundamental_freq)
    harmonic_history.append(current_result)
    
    # –í—Ä–µ–º–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    if len(harmonic_history) < HARMONIC_HISTORY_SIZE // 2: 
        return False, fundamental_freq, drone_type, confidence
    
    positive_count = sum(harmonic_history)
    total_count = len(harmonic_history)
    positive_ratio = positive_count / total_count if total_count > 0 else 0
    
    if positive_ratio >= CONFIRMATION_THRESHOLD:
        if frequency_history:
            confirmed_frequency = np.median(list(frequency_history)[-10:])
        else:
            confirmed_frequency = fundamental_freq
        
        detected_drone_type = drone_type
        detection_confidence = confidence
        return True, confirmed_frequency, drone_type, confidence
    
    return False, fundamental_freq, drone_type, confidence

# –§–£–ù–ö–¶–ò–ò –ú–ò–ö–†–û–§–û–ù–ê

def get_available_microphones(): #–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–∏–∫—Ä–æ—Ñ–æ–Ω–æ–≤
    microphones = []
    info = audio_engine.get_host_api_info_by_index(0)
    num_devices = info.get('deviceCount')
    
    for i in range(num_devices):
        device_info = audio_engine.get_device_info_by_host_api_device_index(0, i)
        if device_info.get('maxInputChannels') > 0:
            device_name = device_info.get('name')
            microphones.append((i, device_name))
    
    return microphones

def create_stream(buffer, rate, device_index=None): #–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–∞
    try:
        stream = audio_engine.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=rate,
            input=True,
            input_device_index=device_index,
            frames_per_buffer=buffer,
            stream_callback=None
        )
        return stream
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ—Ç–æ–∫–∞: {e}")
        return None

def safe_exit(): #–ë–µ–∑–æ–ø–∞—Å–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º—É
    global running
    running = False
    
    print("\n\n–ó–∞–∫—Ä—ã–≤–∞—é –ø—Ä–æ–≥—Ä–∞–º–º—É...")
    
    try:
        if 'audio_stream' in globals() and audio_stream is not None:
            audio_stream.stop_stream()
            audio_stream.close()
            print("–ê—É–¥–∏–æ–ø–æ—Ç–æ–∫ –∑–∞–∫—Ä—ã—Ç")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –ø–æ—Ç–æ–∫–∞: {e}")
    
    try:
        if 'audio_engine' in globals():
            audio_engine.terminate()
            print("–ê—É–¥–∏–æ–¥–≤–∏–∂–æ–∫ –∑–∞–∫—Ä—ã—Ç")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –¥–≤–∏–∂–∫–∞: {e}")
    
    sys.exit(0)

# –ì–õ–ê–í–ù–´–ô –¶–ò–ö–õ –û–ë–†–ê–ë–û–¢–ö–ò –ê–£–î–ò–û

def audio_processing_thread(): #–ü–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ
    global running, detection_active, last_detection_time
    
    print("\n" + "="*70)
    print("–î–ï–¢–ï–ö–¢–û–† –î–†–û–ù–û–í - HYBRID VERSION")
    print("="*70)
    print(f"–£—Å—Ç–∞–Ω–æ–≤–∫–∞: {INSTALLATION_ID.upper()}")
    print(f"–°–µ—Ä–≤–µ—Ä: {SERVER_URL}")
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: SR={SAMPLE_RATE}Hz, FFT={FFT_SIZE}, Welch={WELCH_SEGMENT}/{WELCH_OVERLAP}")
    print(f"–ê–ª–≥–æ—Ä–∏—Ç–º")
    print("="*70 + "\n")
    
    frame_count = 0
    detection_history_text = ""
    
    while running:
        try:
            # –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ
            raw_audio = np.frombuffer(
                audio_stream.read(BUFFER_SIZE, exception_on_overflow=False),
                dtype=np.int16
            ).astype(np.float32)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            raw_audio = raw_audio / 32768.0
            
            # HIGH-PASS —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
            filtered = sosfilt(butter_sos, raw_audio)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å–ø–µ–∫—Ç—Ä
            frequency_axis, magnitude_log = compute_welch_spectrum(
                filtered, SAMPLE_RATE, WELCH_SEGMENT, WELCH_OVERLAP
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–∞—Ä–º–æ–Ω–∏–∫–∏
            harmonics_confirmed, current_freq, drone_type, confidence = \
                check_harmonics_with_delay_enhanced(frequency_axis, magnitude_log)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –¥–µ—Ç–µ–∫—Ü–∏–∏
            if harmonics_confirmed and confidence > 0.5:
                detection_active = True
                last_detection_time = time.time()
                indicator_color = "üü¢"
            else:
                # –î–µ—Ä–∂–∏–º –¥–µ—Ç–µ–∫—Ü–∏—é –∞–∫—Ç–∏–≤–Ω–æ–π 0.5 —Å–µ–∫ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
                if time.time() - last_detection_time > 0.5:
                    detection_active = False
                indicator_color = "üü¢" if detection_active else "üî¥"
            
            # –û–¢–ü–†–ê–í–õ–Ø–ï–ú –î–ê–ù–ù–´–ï –ù–ê –°–ï–†–í–ï–†
            send_to_server(detection_active, current_freq, drone_type.value, confidence)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å—Ç–∞—Ç—É—Å–∞
            frame_count += 1
            if frame_count % 10 == 0:  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–µ 10 –∫–∞–¥—Ä–æ–≤ (~500ms)
                freq_str = f"{current_freq:.0f}" if current_freq else "---"
                conf_str = f"{confidence:.0%}" if confidence > 0 else "---"
                type_str = drone_type.value if drone_type != DroneType.UNKNOWN else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                
                # –ò—Å—Ç–æ—Ä–∏—è: + –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ, - –µ—Å–ª–∏ –Ω–µ—Ç
                if len(harmonic_history) > 0:
                    detection_history_text = "".join(
                        ["+" if h else "-" for h in list(harmonic_history)[-20:]]
                    )
                
                print(
                    f"\r{indicator_color} F:{freq_str:>6}Hz | "
                    f"Conf:{conf_str:>4} | Type:{type_str:15} | "
                    f"Status:{'DETECTED' if detection_active else 'CLEAR':10} | "
                    f"–ò—Å—Ç–æ—Ä–∏—è: {detection_history_text:20}",
                    end='', flush=True
                )
            
            # time.sleep –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
            time.sleep(0.001)
        
        except IOError as e:
            print(f"\n–û—à–∏–±–∫–∞ –±—É—Ñ–µ—Ä–∞: {e}")
            time.sleep(0.1)
        except Exception as e:
            print(f"\n–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            time.sleep(0.1)


# –ì–õ–ê–í–ù–ê–Ø –ü–†–û–ì–†–ê–ú–ú–ê

if __name__ == "__main__":
    try:
        # –ü–æ–ª—É—á–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω—ã
        microphones = get_available_microphones()
        if not microphones:
            print("‚ö†Ô∏è –ú–∏–∫—Ä–æ—Ñ–æ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ.")
            sys.exit(1)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –º–∏–∫—Ä–æ—Ñ–æ–Ω
        current_device_index = microphones[0][0]
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–∏–∫—Ä–æ—Ñ–æ–Ω: {microphones[0][1]}")
        
        # –°–æ–∑–¥–∞–µ–º –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫
        audio_stream = create_stream(BUFFER_SIZE, SAMPLE_RATE, current_device_index)
        if audio_stream is None:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫!")
            sys.exit(1)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ
        audio_thread = Thread(target=audio_processing_thread, daemon=True)
        audio_thread.start()
        
        print(f"\n–î–µ—Ç–µ–∫—Ç–æ—Ä –∑–∞–ø—É—â–µ–Ω (—É—Å—Ç–∞–Ω–æ–≤–∫–∞: {INSTALLATION_ID.upper()})")
        print("–û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Å–µ—Ä–≤–µ—Ä –∞–∫—Ç–∏–≤–Ω–∞")
        print("–ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n")
        
        # –î–µ—Ä–∂–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã–º
        while running:
            time.sleep(0.1)
    
    except KeyboardInterrupt:
        print("\n\n–ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ (Ctrl+C)")
    except Exception as e:
        print(f"\n–û—à–∏–±–∫–∞: {e}")
    finally:
        safe_exit()
